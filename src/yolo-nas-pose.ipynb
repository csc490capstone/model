{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gaVRJWoyu0aP"
      },
      "id": "gaVRJWoyu0aP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install super-gradients"
      ],
      "metadata": {
        "id": "tOmDi6A5Oohe"
      },
      "id": "tOmDi6A5Oohe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from super_gradients.training import models\n",
        "from super_gradients.common.object_names import Models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "HJXS29uyun4q"
      },
      "id": "HJXS29uyun4q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_HPE_model(device):\n",
        "    # Initialise machine learning model\n",
        "    yolo_nas_pose = models.get(\"yolo_nas_pose_l\", pretrained_weights=\"coco_pose\").to(device)\n",
        "    return yolo_nas_pose\n",
        "\n",
        "def predict_image(HPE_model, input_path, confidence):\n",
        "    result = HPE_model.predict(input_path, conf=confidence)\n",
        "    return result\n",
        "\n",
        "def extract_poses(result):\n",
        "    poses = result.prediction.poses\n",
        "    landmarks = np.array([])\n",
        "    for person, pose in enumerate(poses):\n",
        "        landmarks = np.concatenate((landmarks, pose.flatten()))\n",
        "\n",
        "    landmarks.flatten()\n",
        "    return landmarks\n",
        "\n",
        "def draw_keypoints(result, color):\n",
        "    keypoint_colors = color * 17\n",
        "    edge_colors = color * 19\n",
        "\n",
        "    image = result.draw(\n",
        "        edge_colors=edge_colors,\n",
        "        joint_thickness=5,\n",
        "        keypoint_colors=keypoint_colors,\n",
        "        keypoint_radius=10,\n",
        "        box_thickness=5,\n",
        "        show_confidence=True,\n",
        "    )\n",
        "    return image\n",
        "\n",
        "def annotate_image(image, text, confidence, color=(255, 0, 0)):\n",
        "    font = cv2.FONT_HERSHEY_DUPLEX\n",
        "    org1 = (25, 50)\n",
        "    org2 = (25, 100)\n",
        "    fontScale = 1\n",
        "    thickness = 3\n",
        "    image = cv2.putText(image, text, org1, font, fontScale,\n",
        "                        color, thickness, cv2.LINE_AA, False)\n",
        "    image = cv2.putText(image, str(confidence), org2, font, fontScale,\n",
        "                        color, thickness, cv2.LINE_AA, False)\n",
        "\n",
        "    return image\n",
        "\n",
        "def save_image(filename, image):\n",
        "    cv2.imwrite(filename, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "id": "93_rLXgturFP"
      },
      "id": "93_rLXgturFP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If GPU available, use it\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "# Initialize the Human Pose Estimation (HPE) model\n",
        "yolo_nas_pose = init_HPE_model(device)\n",
        "\n",
        "# Define the path to your images in Google Drive\n",
        "image_folder_path = \"/content/drive/My Drive/your_folder_name/\"  # Replace with your folder path\n",
        "\n",
        "# List all image files in the folder\n",
        "image_files = [os.path.join(image_folder_path, f) for f in os.listdir(image_folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Process each image\n",
        "for image_path in image_files:\n",
        "    # Predict keypoints on the image\n",
        "    result = predict_image(yolo_nas_pose, image_path, confidence=0.3)\n",
        "\n",
        "    # Draw keypoints on the image\n",
        "    color = (0, 255, 0)  # Green color for keypoints\n",
        "    image_with_keypoints = draw_keypoints(result, [color])\n",
        "\n",
        "    # Annotate the image with confidence score\n",
        "    image_with_keypoints = annotate_image(image_with_keypoints, text=\"Keypoints Detected\", confidence=0.0, color=color)\n",
        "\n",
        "    # Save the annotated image to Google Drive\n",
        "    output_filename = os.path.join(image_folder_path, f\"annotated_{os.path.basename(image_path)}\")\n",
        "    save_image(output_filename, image_with_keypoints)\n",
        "\n",
        "    # Display the annotated image\n",
        "    plt.imshow(cv2.cvtColor(image_with_keypoints, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "B0O9UAnVur7H"
      },
      "id": "B0O9UAnVur7H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Nc7ElFfuySj"
      },
      "id": "-Nc7ElFfuySj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}